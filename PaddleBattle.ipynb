{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压数据集\n",
    "# !unzip -oq /home/aistudio/data/data100477/常规赛：PALM眼底彩照中黄斑中央凹定位.zip\n",
    "# !rm -rf __MACOSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "import blackhole.dataframe as pd  # 数据读取\r\n",
    "import paddle.vision.transforms as T  # 数据增强\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import paddle\r\n",
    "import cv2\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 P0198.jpg\n",
      "[(2056, 2124, 3), (1444, 1444, 3)]\n"
     ]
    }
   ],
   "source": [
    "# 我的测试\r\n",
    "file_path='常规赛：PALM眼底彩照中黄斑中央凹定位/Train/fundus_image/'\r\n",
    "# file_path='常规赛：PALM眼底彩照中黄斑中央凹定位/PALM-Testing400-Images/'\r\n",
    "# file_name='H0001.jpg'\r\n",
    "list_=os.listdir(file_path)\r\n",
    "print(len(list_),list_[0])\r\n",
    "shapes=[]\r\n",
    "for f in list_:\r\n",
    "    img=cv2.imread(file_path+f,-1)\r\n",
    "    a=img.shape\r\n",
    "    if(shapes.count(a)==0):\r\n",
    "        shapes.append(a)\r\n",
    "print(shapes)\r\n",
    "# plt.imshow(img[:,:,[2,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgName</th>\n",
       "      <th>Fovea_X</th>\n",
       "      <th>Fovea_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H0001.jpg</td>\n",
       "      <td>743.96</td>\n",
       "      <td>790.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imgName  Fovea_X  Fovea_Y\n",
       "0  H0001.jpg   743.96   790.54"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据标签\r\n",
    "df=pd.read_excel('常规赛：PALM眼底彩照中黄斑中央凹定位/Train/Fovea_Location_train.xlsx')\r\n",
    "df.head(1)\r\n",
    "# print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签的均值为: 1085.6073687500023\n",
      "标签的标准差为: 183.5345073716085\n"
     ]
    }
   ],
   "source": [
    "# 计算标签的均值和标准差，用于标签的归一化\r\n",
    "key_pts_values = df.values[:,1:] # 取出标签信息\r\n",
    "data_mean = key_pts_values.mean() # 计算均值\r\n",
    "data_std = key_pts_values.std() # 计算标准差\r\n",
    "\r\n",
    "print('标签的均值为:', data_mean)\r\n",
    "print('标签的标准差为:', data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据增强：调整图像大小Resize、随机位置裁剪RandomCrop、灰度化图片GrayNormalize、变更图片通道ToCHW\r\n",
    "import paddle.vision.transforms.functional as F\r\n",
    "\r\n",
    "# 调整图像大小\r\n",
    "class Resize(object):\r\n",
    "    # 将输入图像调整为指定大小\r\n",
    "    def __init__(self, output_size):\r\n",
    "        assert isinstance(output_size, (int, tuple))\r\n",
    "        self.output_size = output_size\r\n",
    "\r\n",
    "    def __call__(self, data):\r\n",
    "        image = data[0]    # 获取图片\r\n",
    "        key_pts = data[1]  # 获取标签\r\n",
    "\r\n",
    "        image_copy = np.copy(image)      \r\n",
    "        key_pts_copy = np.copy(key_pts)\r\n",
    "\r\n",
    "        h, w = image_copy.shape[:2]\r\n",
    "\r\n",
    "        new_h, new_w = self.output_size,self.output_size\r\n",
    "\r\n",
    "        new_h, new_w = int(new_h), int(new_w)\r\n",
    "\r\n",
    "        img = F.resize(image_copy, (new_h, new_w))\r\n",
    "        \r\n",
    "        # scale the pts, too\r\n",
    "        key_pts_copy[::2] = key_pts_copy[::2] * new_w / w\r\n",
    "        key_pts_copy[1::2] = key_pts_copy[1::2] * new_h / h\r\n",
    "\r\n",
    "        return img, key_pts_copy\r\n",
    "\r\n",
    "# 随机位置裁剪\r\n",
    "class RandomCrop(object):\r\n",
    "    # 随机位置裁剪输入的图像\r\n",
    "    def __init__(self, output_size):\r\n",
    "        assert isinstance(output_size, (int, tuple))\r\n",
    "        if isinstance(output_size, int):\r\n",
    "            self.output_size = (output_size, output_size)\r\n",
    "        else:\r\n",
    "            assert len(output_size) == 2\r\n",
    "            self.output_size = output_size\r\n",
    "\r\n",
    "    def __call__(self, data):\r\n",
    "        image = data[0]\r\n",
    "        key_pts = data[1]\r\n",
    "\r\n",
    "        image_copy = np.copy(image)\r\n",
    "        key_pts_copy = np.copy(key_pts)\r\n",
    "\r\n",
    "        h, w = image_copy.shape[:2]\r\n",
    "        new_h, new_w = self.output_size\r\n",
    "\r\n",
    "        top = np.random.randint(0, h - new_h)\r\n",
    "        left = np.random.randint(0, w - new_w)\r\n",
    "\r\n",
    "        image_copy = image_copy[top: top + new_h,\r\n",
    "                      left: left + new_w]\r\n",
    "\r\n",
    "        key_pts_copy[::2] = key_pts_copy[::2] - left\r\n",
    "        key_pts_copy[1::2] = key_pts_copy[1::2] - top\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "        return image_copy, key_pts_copy\r\n",
    "\r\n",
    "# 图片灰度化\r\n",
    "class GrayNormalize(object):\r\n",
    "    # 将图片变为灰度图，并将其值放缩到[0, 1]\r\n",
    "    # 将 label 放缩到 [-1, 1] 之间\r\n",
    "    def __call__(self, data):\r\n",
    "        image = data[0]   # 获取图片\r\n",
    "        key_pts = data[1] # 获取标签\r\n",
    "        \r\n",
    "        image_copy = np.copy(image)\r\n",
    "        key_pts_copy = np.copy(key_pts)\r\n",
    "\r\n",
    "        # 灰度化图片\r\n",
    "        gray_scale = paddle.vision.transforms.Grayscale(num_output_channels=3)\r\n",
    "        image_copy = gray_scale(image_copy)\r\n",
    "        \r\n",
    "        # 将图片值放缩到 [0, 1]\r\n",
    "        image_copy = (image_copy-127.5) / 127.5\r\n",
    "        \r\n",
    "        # 将坐标点放缩到 [-1, 1]\r\n",
    "        mean = data_mean # 获取标签均值\r\n",
    "        std = data_std   # 获取标签标准差\r\n",
    "\r\n",
    "        key_pts_copy = (key_pts_copy - mean)/std\r\n",
    "\r\n",
    "        return image_copy, key_pts_copy\r\n",
    "\r\n",
    "# 变更图片通道\r\n",
    "class ToCHW(object):\r\n",
    "    # 将图像的格式由HWC改为CHW\r\n",
    "    def __call__(self, data):\r\n",
    "        image = data[0]\r\n",
    "        key_pts = data[1]\r\n",
    "\r\n",
    "        transpose = T.Transpose((2, 0, 1)) # 改为CHW\r\n",
    "        image = transpose(image)\r\n",
    "        \r\n",
    "        return image, key_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用自定义类进行数据预处理\r\n",
    "data_transform = T.Compose([\r\n",
    "                        Resize(240),   # 240 1444\r\n",
    "                        RandomCrop(224),\r\n",
    "                        GrayNormalize(),\r\n",
    "                        ToCHW(),\r\n",
    "                         ])\r\n",
    "data_transform2 = T.Compose([\r\n",
    "                        Resize(240),    # 240 1444\r\n",
    "                        GrayNormalize(),\r\n",
    "                        ToCHW(),\r\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用飞桨的数据增强\r\n",
    "import paddle.vision.transforms as T\r\n",
    "train_transform = T.Compose([\r\n",
    "                        T.Resize(size=[240,240]),    # 压缩图像大小 1444\r\n",
    "                        # T.CenterCrop(1440), # 保持图片中心不变并进行裁剪\r\n",
    "                        T.ColorJitter(0.1, 0.1, 0.1, 0.1), #　随机调整图像的亮度，对比度，饱和度和色调。\r\n",
    "                        T.RandomVerticalFlip(0.3),  # 基于概率来执行图片的垂直翻转。\r\n",
    "                        T.RandomHorizontalFlip(0.3),  # 基于概率来执行图片的水平翻转。\r\n",
    "                        T.RandomRotation(30),  # 随机旋转\r\n",
    "                        T.Normalize(mean=[127.5, 127.5, 127.5],std=[127.5, 127.5, 127.5],data_format='HWC'),  # 归一化\r\n",
    "                        T.ToTensor(),\r\n",
    "                        ])\r\n",
    "val_transform=T.Compose([\r\n",
    "                        T.Resize(size=[240,240]),  # 1440\r\n",
    "                        T.Normalize(mean=[127.5, 127.5, 127.5],std=[127.5, 127.5, 127.5],data_format='HWC'),\r\n",
    "                        T.ToTensor(),\r\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 自定义数据集\r\n",
    "path='常规赛：PALM眼底彩照中黄斑中央凹定位/Train/fundus_image/'\r\n",
    "df=df.sample(frac=1)\r\n",
    "image_list=[]\r\n",
    "label_listx=[]\r\n",
    "label_listy=[]\r\n",
    "\r\n",
    "for i in range(len(df)):\r\n",
    "        image_list.append(path+df['imgName'][i])\r\n",
    "        label_listx.append(df['Fovea_X'][i])\r\n",
    "        label_listy.append(df['Fovea_Y'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "test_path='常规赛：PALM眼底彩照中黄斑中央凹定位/PALM-Testing400-Images'\r\n",
    "test_list=[]\r\n",
    "test_labelx=[]\r\n",
    "test_labely=[]\r\n",
    "\r\n",
    "list = os.listdir(test_path)  # 列出文件夹下所有的目录与文件\r\n",
    "for i in range(0, len(list)):\r\n",
    "    path = os.path.join(test_path, list[i])\r\n",
    "    test_list.append(path)\r\n",
    "    test_labelx.append(0)\r\n",
    "    test_labely.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义数据集类\r\n",
    "class dataset(paddle.io.Dataset):\r\n",
    "    def __init__(self,img_list,label_listx,label_listy,transform=None,transform2=None,mode='train'):\r\n",
    "\r\n",
    "        self.image=img_list\r\n",
    "        self.labelx=label_listx\r\n",
    "        self.labely=label_listy\r\n",
    "        self.mode=mode\r\n",
    "        self.transform=transform\r\n",
    "        self.transform2=transform2\r\n",
    "    def load_img(self, image_path):\r\n",
    "\r\n",
    "        img=cv2.imread(image_path,1)\r\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\r\n",
    "        return img\r\n",
    "\r\n",
    "\r\n",
    "    def __getitem__(self,index):\r\n",
    "        img = self.load_img(self.image[index])\r\n",
    "        labelx = self.labelx[index]\r\n",
    "        labely = self.labely[index]\r\n",
    "        img_size=img.shape\r\n",
    "\r\n",
    "        if self.transform:\r\n",
    "            if self.mode=='train':\r\n",
    "                img, label = self.transform([img, [labelx,labely]])\r\n",
    "            else:\r\n",
    "                img, label = self.transform2([img, [labelx,labely]])\r\n",
    "\r\n",
    "        label=np.array(label,dtype='float32')\r\n",
    "        img=np.array(img,dtype='float32')\r\n",
    "        return img,label\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练集、验证集、测试集\r\n",
    "radio=0.8\r\n",
    "train_list=image_list[:int(len(image_list)*radio)]\r\n",
    "train_labelx=label_listx[:int(len(label_listx)*radio)]\r\n",
    "train_labely=label_listy[:int(len(label_listy)*radio)]\r\n",
    "\r\n",
    "\r\n",
    "val_list=image_list[int(len(image_list)*radio):]\r\n",
    "val_labelx=label_listx[int(len(label_listx)*radio):]\r\n",
    "val_labely=label_listy[int(len(label_listy)*radio):]\r\n",
    "\r\n",
    "\r\n",
    "train_ds=dataset(train_list,train_labelx,train_labely,data_transform,data_transform2,'train')\r\n",
    "val_ds=dataset(val_list,val_labelx,val_labely,data_transform,data_transform2,'valid')\r\n",
    "test_ds=dataset(test_list,test_labelx,test_labely,data_transform,data_transform2,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看图片\r\n",
    "for i,data in enumerate(train_ds):\r\n",
    "    \r\n",
    "    img,label=data\r\n",
    "\r\n",
    "    img=img.transpose([1,2,0])\r\n",
    "    print(img.shape)\r\n",
    "    \r\n",
    "    plt.title(label)\r\n",
    "    plt.imshow(img)\r\n",
    "    \r\n",
    "\r\n",
    "    if i==0:\r\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 前向网络构建\r\n",
    "class MyNet1(paddle.nn.Layer):\r\n",
    "    def __init__(self,num_classes=2):\r\n",
    "        super(MyNet1,self).__init__()\r\n",
    "        self.net=paddle.vision.resnet152(pretrained=True)\r\n",
    "\r\n",
    "        self.fc1=paddle.nn.Linear(1000,512)\r\n",
    "        self.relu=paddle.nn.ReLU()\r\n",
    "        self.fc2=paddle.nn.Linear(512,num_classes)\r\n",
    "\r\n",
    "    def forward(self,inputs):\r\n",
    "        out=self.net(inputs)\r\n",
    "\r\n",
    "        out=self.fc1(out)\r\n",
    "        out=self.relu(out)\r\n",
    "        out=self.fc2(out)\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "class MyNet2(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(MyNet2, self).__init__()\r\n",
    "        self.resnet = paddle.vision.resnet50(pretrained=True, num_classes=0) # remove final fc 输出为[?, 2048, 1, 1]\r\n",
    "        self.flatten = paddle.nn.Flatten()\r\n",
    "        self.linear_1 = paddle.nn.Linear(2048, 512)\r\n",
    "        self.linear_2 = paddle.nn.Linear(512, 256)\r\n",
    "        self.linear_3 = paddle.nn.Linear(256, 2)\r\n",
    "        self.relu = paddle.nn.ReLU()\r\n",
    "        self.dropout = paddle.nn.Dropout(0.2)\r\n",
    "    \r\n",
    "    def forward(self, inputs):\r\n",
    "\r\n",
    "        y = self.resnet(inputs)\r\n",
    "        y = self.flatten(y)\r\n",
    "        y = self.linear_1(y)\r\n",
    "        y = self.linear_2(y)\r\n",
    "        y = self.relu(y)\r\n",
    "        y = self.dropout(y)\r\n",
    "        y = self.linear_3(y)\r\n",
    "        y = paddle.nn.functional.sigmoid(y)\r\n",
    "\r\n",
    "        return y\r\n",
    "\r\n",
    "class MyNet3(paddle.nn.Layer):\r\n",
    "    def __init__(self,num_classes=2):\r\n",
    "        super(MyNet3,self).__init__()\r\n",
    "        self.net=paddle.vision.resnet152(pretrained=True)\r\n",
    "\r\n",
    "        self.fc1=paddle.nn.Linear(1000,2000)\r\n",
    "        self.relu=paddle.nn.ReLU()\r\n",
    "        self.dropout1 = paddle.nn.Dropout(0.2)\r\n",
    "        self.fc2=paddle.nn.Linear(2000,num_classes)\r\n",
    "\r\n",
    "    def forward(self,inputs):\r\n",
    "        out=self.net(inputs)\r\n",
    "\r\n",
    "        out=self.fc1(out)\r\n",
    "        out=self.relu(out)\r\n",
    "        out = self.dropout1(out)\r\n",
    "        out=self.fc2(out)\r\n",
    "\r\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 自定义损失函数和相关类\r\n",
    "from sklearn.metrics.pairwise import euclidean_distances \r\n",
    "import paddle.nn as nn\r\n",
    "# 损失函数\r\n",
    "def cal_coordinate_Loss(logit, label, alpha = 0.5):\r\n",
    "    \"\"\"\r\n",
    "    logit: shape [batch, ndim]\r\n",
    "    label: shape [batch, ndim]\r\n",
    "    ndim = 2 represents coordinate_x and coordinaate_y\r\n",
    "    alpha: weight for MSELoss and 1-alpha for ED loss\r\n",
    "    return: combine MSELoss and ED Loss for x and y, shape [batch, 1]\r\n",
    "    \"\"\"\r\n",
    "    alpha = alpha\r\n",
    "    mse_loss = nn.MSELoss(reduction='mean')\r\n",
    "\r\n",
    "    mse_x = mse_loss(logit[:,0],label[:,0])\r\n",
    "    mse_y = mse_loss(logit[:,1],label[:,1])\r\n",
    "    mse_l = 0.5*(mse_x + mse_y)\r\n",
    "    # print('mse_l', mse_l)\r\n",
    "\r\n",
    "    ed_loss = []\r\n",
    "    # print(logit.shape[0])\r\n",
    "    for i in range(logit.shape[0]):\r\n",
    "        logit_tmp = logit[i,:].numpy()\r\n",
    "        label_tmp = label[i,:].numpy()\r\n",
    "        # print('cal_coordinate_loss_ed', logit_tmp, label_tmp)        \r\n",
    "        ed_tmp = euclidean_distances([logit_tmp], [label_tmp])\r\n",
    "        # print('ed_tmp:', ed_tmp[0][0])\r\n",
    "        ed_loss.append(ed_tmp)\r\n",
    "    \r\n",
    "    ed_l = sum(ed_loss)/len(ed_loss)\r\n",
    "    # print('ed_l', ed_l)\r\n",
    "    # print('alpha', alpha)\r\n",
    "    loss = alpha * mse_l + (1-alpha) * ed_l\r\n",
    "    # print('loss in function', loss)\r\n",
    "    return loss\r\n",
    "\r\n",
    "class SelfDefineLoss(paddle.nn.Layer):\r\n",
    "   \"\"\"\r\n",
    "   1. 继承paddle.nn.Layer\r\n",
    "   \"\"\"\r\n",
    "   def __init__(self):\r\n",
    "       \"\"\"\r\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\r\n",
    "       \"\"\"\r\n",
    "       super(SelfDefineLoss, self).__init__()\r\n",
    "\r\n",
    "   def forward(self, input, label):\r\n",
    "       \"\"\"\r\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\r\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\r\n",
    "           - label：单个或批次训练数据对应的标签数据\r\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\r\n",
    "       \"\"\"\r\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\r\n",
    "       output = cal_coordinate_Loss(input,label)\r\n",
    "       return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 异步数据加载\r\n",
    "train_loader = paddle.io.DataLoader(train_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=True, num_workers=0)\r\n",
    "val_loader = paddle.io.DataLoader(val_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=False, num_workers=0)\r\n",
    "test_loader=paddle.io.DataLoader(test_ds, places=paddle.CPUPlace(), batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1103 09:17:01.086086   793 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1103 09:17:01.143574   793 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "100%|██████████| 355826/355826 [00:05<00:00, 60144.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20/20 [==============================] - loss: 0.7987 - nme: 2.6488 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/0\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.4149 - nme: 0.9242 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 2/30\n",
      "step 20/20 [==============================] - loss: 0.2826 - nme: 0.9553 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/1\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1146 - nme: 0.4539 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 3/30\n",
      "step 20/20 [==============================] - loss: 0.1658 - nme: 0.5793 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/2\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.2310 - nme: 0.6559 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 4/30\n",
      "step 20/20 [==============================] - loss: 0.1159 - nme: 0.4710 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/3\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1429 - nme: 0.5067 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 5/30\n",
      "step 20/20 [==============================] - loss: 0.1510 - nme: 0.4463 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/4\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1438 - nme: 0.5093 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 6/30\n",
      "step 20/20 [==============================] - loss: 0.0940 - nme: 0.4155 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/5\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1566 - nme: 0.5409 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 7/30\n",
      "step 20/20 [==============================] - loss: 0.0941 - nme: 0.3596 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/6\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.0865 - nme: 0.3944 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 8/30\n",
      "step 20/20 [==============================] - loss: 0.0837 - nme: 0.3401 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/7\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.0954 - nme: 0.4186 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 9/30\n",
      "step 20/20 [==============================] - loss: 0.0764 - nme: 0.3059 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/8\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1321 - nme: 0.4985 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 10/30\n",
      "step 20/20 [==============================] - loss: 0.0672 - nme: 0.2892 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/9\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1368 - nme: 0.5099 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 11/30\n",
      "step 20/20 [==============================] - loss: 0.0713 - nme: 0.2982 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/10\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1440 - nme: 0.5265 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 12/30\n",
      "step 20/20 [==============================] - loss: 0.0416 - nme: 0.2838 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/11\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1317 - nme: 0.5012 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 13/30\n",
      "step 20/20 [==============================] - loss: 0.0757 - nme: 0.2954 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/12\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1271 - nme: 0.4918 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 14/30\n",
      "step 20/20 [==============================] - loss: 0.0560 - nme: 0.2822 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/13\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1324 - nme: 0.5028 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 15/30\n",
      "step 20/20 [==============================] - loss: 0.0384 - nme: 0.2844 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/14\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1286 - nme: 0.4951 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 16/30\n",
      "step 20/20 [==============================] - loss: 0.0311 - nme: 0.2622 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/15\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1396 - nme: 0.5175 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 17/30\n",
      "step 20/20 [==============================] - loss: 0.0295 - nme: 0.2478 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/16\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1428 - nme: 0.5241 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 18/30\n",
      "step 20/20 [==============================] - loss: 0.0353 - nme: 0.2498 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/17\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1311 - nme: 0.5022 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 19/30\n",
      "step 20/20 [==============================] - loss: 0.0592 - nme: 0.2613 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/18\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1724 - nme: 0.5790 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 20/30\n",
      "step 20/20 [==============================] - loss: 0.0406 - nme: 0.2497 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/19\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1306 - nme: 0.5024 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 21/30\n",
      "step 20/20 [==============================] - loss: 0.0434 - nme: 0.2470 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/20\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1318 - nme: 0.5058 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 22/30\n",
      "step 20/20 [==============================] - loss: 0.0614 - nme: 0.2457 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/21\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1279 - nme: 0.4982 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 23/30\n",
      "step 20/20 [==============================] - loss: 0.0299 - nme: 0.2425 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/22\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1587 - nme: 0.5565 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 24/30\n",
      "step 20/20 [==============================] - loss: 0.0497 - nme: 0.2503 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/23\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1598 - nme: 0.5578 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 25/30\n",
      "step 20/20 [==============================] - loss: 0.0293 - nme: 0.2325 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/24\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1421 - nme: 0.5261 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 26/30\n",
      "step 20/20 [==============================] - loss: 0.0703 - nme: 0.2421 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/25\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1597 - nme: 0.5580 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 27/30\n",
      "step 20/20 [==============================] - loss: 0.0381 - nme: 0.2337 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/26\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1566 - nme: 0.5520 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 28/30\n",
      "step 20/20 [==============================] - loss: 0.0367 - nme: 0.2362 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/27\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1641 - nme: 0.5649 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 29/30\n",
      "step 20/20 [==============================] - loss: 0.0336 - nme: 0.2359 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/28\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1572 - nme: 0.5528 - 2s/step\n",
      "Eval samples: 160\n",
      "Epoch 30/30\n",
      "step 20/20 [==============================] - loss: 0.0426 - nme: 0.2294 - 2s/step          \n",
      "save checkpoint at /home/aistudio/work/lup/29\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1618 - nme: 0.5614 - 2s/step\n",
      "Eval samples: 160\n",
      "save checkpoint at /home/aistudio/work/lup/final\n"
     ]
    }
   ],
   "source": [
    "# 模型训练与可视化\r\n",
    "from utils import NME\r\n",
    "visualdl=paddle.callbacks.VisualDL(log_dir='visual_log')\r\n",
    "#定义输入\r\n",
    "\r\n",
    "Batch_size=32    # 每批训练数据的大小\r\n",
    "EPOCHS=30    # 训练的总次数\r\n",
    "step_each_epoch = len(train_ds)//Batch_size\r\n",
    "\r\n",
    "# 使用 paddle.Model 封装模型\r\n",
    "model = paddle.Model(MyNet3())  # num_classes=2\r\n",
    "\r\n",
    "lr = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=3e-4,    # 学习率初始值\r\n",
    "                                            #   eta_min=1e-5,    # 学习率最终值，默认0\r\n",
    "                                              T_max=step_each_epoch * EPOCHS)\r\n",
    "\r\n",
    "# 定义Adam优化器\r\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=lr,\r\n",
    "                                weight_decay=1e-4,    # 正则化系数 1e-4\r\n",
    "                                parameters=model.parameters())\r\n",
    "# 定义损失：SmoothL1Loss\r\n",
    "# loss =paddle.nn.SmoothL1Loss()\r\n",
    "# loss =SelfDefineLoss()\r\n",
    "loss=paddle.nn.MSELoss(reduction='mean')\r\n",
    "\r\n",
    "# 使用自定义metrics\r\n",
    "metric = NME()\r\n",
    "\r\n",
    "model.prepare(optimizer=optimizer, loss=loss, metrics=metric)\r\n",
    "\r\n",
    "# model.load('/home/aistudio/work/lup/final')\r\n",
    "\r\n",
    "# 启动模型全流程训练\r\n",
    "model.fit(train_loader,  # 训练数据集\r\n",
    "          val_loader,   # 评估数据集\r\n",
    "          epochs=EPOCHS,       # 训练的总轮次\r\n",
    "          batch_size=Batch_size,  # 训练使用的批大小\r\n",
    "          save_dir=\"/home/aistudio/work/lup\", #把模型参数、优化器参数保存至自定义的文件夹\r\n",
    "          save_freq=1,                    #设定每隔多少个epoch保存模型参数及优化器参数\r\n",
    "          verbose=1 ,      # 日志展示形式\r\n",
    "          callbacks=[visualdl]\r\n",
    "          )  # 设置可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.0865 - nme: 0.3944 - 2s/step\n",
      "Eval samples: 160\n",
      "{'loss': [0.086451456], 'nme': 0.39436783910244433}\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\r\n",
    "model.load('/home/aistudio/work/lup/6')  # final\r\n",
    "result = model.evaluate(val_loader, verbose=1)\r\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.4149 - nme: 0.9242 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 0 {'loss': [0.414888], 'nme': 0.924190838912871}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1146 - nme: 0.4539 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 1 {'loss': [0.11456683], 'nme': 0.45386044390660346}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.2310 - nme: 0.6559 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 2 {'loss': [0.23095012], 'nme': 0.6559024192799737}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1429 - nme: 0.5067 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 3 {'loss': [0.14291322], 'nme': 0.506718317263575}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1438 - nme: 0.5093 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 4 {'loss': [0.14382368], 'nme': 0.509342147629029}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1566 - nme: 0.5409 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 5 {'loss': [0.1565929], 'nme': 0.5408927434293265}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.0865 - nme: 0.3944 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 6 {'loss': [0.086451456], 'nme': 0.39436783910244433}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.0954 - nme: 0.4186 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 7 {'loss': [0.09537879], 'nme': 0.41860036902405245}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1321 - nme: 0.4985 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 8 {'loss': [0.13213913], 'nme': 0.4985280312661625}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1368 - nme: 0.5099 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 9 {'loss': [0.13677725], 'nme': 0.5098969043307836}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1440 - nme: 0.5265 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 10 {'loss': [0.14398697], 'nme': 0.5264954607946404}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1317 - nme: 0.5012 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 11 {'loss': [0.13169944], 'nme': 0.5012100576149451}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1271 - nme: 0.4918 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 12 {'loss': [0.12711105], 'nme': 0.4918438072894751}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1324 - nme: 0.5028 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 13 {'loss': [0.13238034], 'nme': 0.5028316447458545}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1286 - nme: 0.4951 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 14 {'loss': [0.12861724], 'nme': 0.4951472901408264}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1396 - nme: 0.5175 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 15 {'loss': [0.13959967], 'nme': 0.5174850913211485}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1428 - nme: 0.5241 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 16 {'loss': [0.1428281], 'nme': 0.5240635786421485}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1311 - nme: 0.5022 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 17 {'loss': [0.13107061], 'nme': 0.5021865387544183}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1724 - nme: 0.5790 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 18 {'loss': [0.17241782], 'nme': 0.5789703697543844}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1306 - nme: 0.5024 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 19 {'loss': [0.13055041], 'nme': 0.5024435445358202}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1318 - nme: 0.5058 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 20 {'loss': [0.131754], 'nme': 0.5058085954976813}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1279 - nme: 0.4982 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 21 {'loss': [0.12792301], 'nme': 0.4982061964152972}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1587 - nme: 0.5565 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 22 {'loss': [0.1587444], 'nme': 0.5565238509271401}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1598 - nme: 0.5578 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 23 {'loss': [0.15977186], 'nme': 0.5577778961147289}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1421 - nme: 0.5261 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 24 {'loss': [0.14210322], 'nme': 0.5260722560892964}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1597 - nme: 0.5580 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 25 {'loss': [0.1596572], 'nme': 0.5579623931391083}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1566 - nme: 0.5520 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 26 {'loss': [0.15658268], 'nme': 0.5520043986413439}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1641 - nme: 0.5649 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 27 {'loss': [0.16409224], 'nme': 0.5649452581251462}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1572 - nme: 0.5528 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 28 {'loss': [0.15716787], 'nme': 0.5528053701754546}\n",
      "Eval begin...\n",
      "step 5/5 [==============================] - loss: 0.1618 - nme: 0.5614 - 2s/step\n",
      "Eval samples: 160\n",
      "no. 29 {'loss': [0.1617815], 'nme': 0.5613786844111014}\n"
     ]
    }
   ],
   "source": [
    "# 模型批量评估\r\n",
    "model_path=\"/home/aistudio/work/lup/\"\r\n",
    "with open('recors/record.txt','w') as f:\r\n",
    "    for i in range(30):\r\n",
    "        model.load('/home/aistudio/work/lup/'+str(i))\r\n",
    "        result = model.evaluate(val_loader, verbose=1)\r\n",
    "        print('no.',i,result)\r\n",
    "        f.write(str(i)+str(result)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 13/13 [==============================] - 2s/step         \n",
      "Predict samples: 400\n"
     ]
    }
   ],
   "source": [
    "# 进行预测操作\r\n",
    "result = model.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取测试图片尺寸和图片名\r\n",
    "test_path='常规赛：PALM眼底彩照中黄斑中央凹定位/PALM-Testing400-Images'\r\n",
    "test_size=[]\r\n",
    "FileName=[]\r\n",
    "for i in range(len(list)):\r\n",
    "    path = os.path.join(test_path, list[i])\r\n",
    "    img=cv2.imread(path,1)\r\n",
    "    test_size.append(img.shape)\r\n",
    "    FileName.append(list[i])\r\n",
    "test_size=np.array(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 输出结果文件\r\n",
    "result=np.array(result)\r\n",
    "pred=[]\r\n",
    "for i in range(len(result[0])):\r\n",
    "    pred.extend(result[0][i])\r\n",
    "pred=np.array(pred) \r\n",
    "\r\n",
    "pred = paddle.to_tensor(pred)\r\n",
    "out=np.array(pred).reshape(-1,2)\r\n",
    "\r\n",
    "Fovea_X=out[:,0]*data_std+data_mean\r\n",
    "Fovea_Y=out[:,1]*data_std+data_mean\r\n",
    "\r\n",
    "Fovea_X=Fovea_X*test_size[:,1]/224\r\n",
    "Fovea_Y=Fovea_Y*test_size[:,0]/224\r\n",
    "\r\n",
    "submission = pd.DataFrame(data={\r\n",
    "                            \"FileName\": FileName,\r\n",
    "                            \"Fovea_X\": Fovea_X,\r\n",
    "                            \"Fovea_Y\": Fovea_Y\r\n",
    "                        })\r\n",
    "submission=submission.sort_values(by='FileName')\r\n",
    "submission.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 合并计算输出\r\n",
    "import numpy as np\r\n",
    "import blackhole.dataframe as pd\r\n",
    "df1=pd.read_csv('result41.958.csv')\r\n",
    "df2=pd.read_csv('result41.958.csv')\r\n",
    "df3=pd.read_csv('result49.65447.csv')\r\n",
    "df4=pd.read_csv('result49.75246.csv')\r\n",
    "\r\n",
    "\r\n",
    "dfs=[df1,df2,df3,df4]\r\n",
    "\r\n",
    "File_Name=[]\r\n",
    "Fovea_X=[]\r\n",
    "Fovea_Y=[]\r\n",
    "for i in range(len(df1)):\r\n",
    "    File_Name.append(dfs[0]['FileName'][i])\r\n",
    "    avgx=(sum(np.array(dfs[x]['Fovea_X'][i]) for x in range(len(dfs))))/len(dfs)\r\n",
    "    avgy=(sum(np.array(dfs[x]['Fovea_Y'][i]) for x in range(len(dfs))))/len(dfs)\r\n",
    "    \r\n",
    "    Fovea_X.append(avgx)\r\n",
    "    Fovea_Y.append(avgy)\r\n",
    "submission = pd.DataFrame(data={\r\n",
    "                            \"FileName\": File_Name,\r\n",
    "                            \"Fovea_X\": Fovea_X,\r\n",
    "                            \"Fovea_Y\":Fovea_Y\r\n",
    "                        })\r\n",
    "submission=submission.sort_values(by='FileName')\r\n",
    "submission.to_csv(\"result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
